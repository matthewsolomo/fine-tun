{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets (from -r requirements.txt (line 2))\n",
      "  Downloading datasets-4.4.2-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting evaluate (from -r requirements.txt (line 3))\n",
      "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting accelerate (from -r requirements.txt (line 4))\n",
      "  Downloading accelerate-1.12.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting scikit-learn (from -r requirements.txt (line 5))\n",
      "  Downloading scikit_learn-1.8.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (11 kB)\n",
      "Collecting pandas (from -r requirements.txt (line 6))\n",
      "  Downloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
      "Collecting numpy (from -r requirements.txt (line 7))\n",
      "  Downloading numpy-2.4.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting transformers[torch] (from -r requirements.txt (line 1))\n",
      "  Downloading transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting filelock (from transformers[torch]->-r requirements.txt (line 1))\n",
      "  Downloading filelock-3.20.2-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers[torch]->-r requirements.txt (line 1))\n",
      "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/codespace/.local/lib/python3.12/site-packages (from transformers[torch]->-r requirements.txt (line 1)) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/codespace/.local/lib/python3.12/site-packages (from transformers[torch]->-r requirements.txt (line 1)) (6.0.3)\n",
      "Collecting regex!=2019.12.17 (from transformers[torch]->-r requirements.txt (line 1))\n",
      "  Downloading regex-2025.11.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /home/codespace/.local/lib/python3.12/site-packages (from transformers[torch]->-r requirements.txt (line 1)) (2.32.5)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers[torch]->-r requirements.txt (line 1))\n",
      "  Downloading tokenizers-0.22.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers[torch]->-r requirements.txt (line 1))\n",
      "  Downloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting tqdm>=4.27 (from transformers[torch]->-r requirements.txt (line 1))\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting torch>=2.2 (from transformers[torch]->-r requirements.txt (line 1))\n",
      "  Downloading torch-2.9.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.34.0->transformers[torch]->-r requirements.txt (line 1))\n",
      "  Downloading fsspec-2025.12.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers[torch]->-r requirements.txt (line 1)) (4.15.0)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.34.0->transformers[torch]->-r requirements.txt (line 1))\n",
      "  Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting pyarrow>=21.0.0 (from datasets->-r requirements.txt (line 2))\n",
      "  Downloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\n",
      "Collecting dill<0.4.1,>=0.3.0 (from datasets->-r requirements.txt (line 2))\n",
      "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: httpx<1.0.0 in /home/codespace/.local/lib/python3.12/site-packages (from datasets->-r requirements.txt (line 2)) (0.28.1)\n",
      "Collecting xxhash (from datasets->-r requirements.txt (line 2))\n",
      "  Downloading xxhash-3.6.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.19 (from datasets->-r requirements.txt (line 2))\n",
      "  Downloading multiprocess-0.70.18-py312-none-any.whl.metadata (7.5 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.34.0->transformers[torch]->-r requirements.txt (line 1))\n",
      "  Downloading fsspec-2025.10.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r requirements.txt (line 2))\n",
      "  Downloading aiohttp-3.13.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)\n",
      "Requirement already satisfied: anyio in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1.0.0->datasets->-r requirements.txt (line 2)) (4.11.0)\n",
      "Requirement already satisfied: certifi in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1.0.0->datasets->-r requirements.txt (line 2)) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1.0.0->datasets->-r requirements.txt (line 2)) (1.0.9)\n",
      "Requirement already satisfied: idna in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1.0.0->datasets->-r requirements.txt (line 2)) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /home/codespace/.local/lib/python3.12/site-packages (from httpcore==1.*->httpx<1.0.0->datasets->-r requirements.txt (line 2)) (0.16.0)\n",
      "Requirement already satisfied: psutil in /home/codespace/.local/lib/python3.12/site-packages (from accelerate->-r requirements.txt (line 4)) (7.1.3)\n",
      "Collecting scipy>=1.10.0 (from scikit-learn->-r requirements.txt (line 5))\n",
      "  Downloading scipy-1.16.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (62 kB)\n",
      "Collecting joblib>=1.3.0 (from scikit-learn->-r requirements.txt (line 5))\n",
      "  Downloading joblib-1.5.3-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting threadpoolctl>=3.2.0 (from scikit-learn->-r requirements.txt (line 5))\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.12/site-packages (from pandas->-r requirements.txt (line 6)) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas->-r requirements.txt (line 6))\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.12/site-packages (from pandas->-r requirements.txt (line 6)) (2025.2)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r requirements.txt (line 2))\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r requirements.txt (line 2))\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/codespace/.local/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r requirements.txt (line 2)) (25.4.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r requirements.txt (line 2))\n",
      "  Downloading frozenlist-1.8.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (20 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r requirements.txt (line 2))\n",
      "  Downloading multidict-6.7.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r requirements.txt (line 2))\n",
      "  Downloading propcache-0.4.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r requirements.txt (line 2))\n",
      "  Downloading yarl-1.22.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (75 kB)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 6)) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests->transformers[torch]->-r requirements.txt (line 1)) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests->transformers[torch]->-r requirements.txt (line 1)) (2.5.0)\n",
      "Requirement already satisfied: setuptools in /home/codespace/.local/lib/python3.12/site-packages (from torch>=2.2->transformers[torch]->-r requirements.txt (line 1)) (80.9.0)\n",
      "Collecting sympy>=1.13.3 (from torch>=2.2->transformers[torch]->-r requirements.txt (line 1))\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx>=2.5.1 (from torch>=2.2->transformers[torch]->-r requirements.txt (line 1))\n",
      "  Downloading networkx-3.6.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.12/site-packages (from torch>=2.2->transformers[torch]->-r requirements.txt (line 1)) (3.1.6)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch>=2.2->transformers[torch]->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch>=2.2->transformers[torch]->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch>=2.2->transformers[torch]->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch>=2.2->transformers[torch]->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch>=2.2->transformers[torch]->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch>=2.2->transformers[torch]->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.9.90 (from torch>=2.2->transformers[torch]->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch>=2.2->transformers[torch]->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch>=2.2->transformers[torch]->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch>=2.2->transformers[torch]->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Collecting nvidia-nccl-cu12==2.27.5 (from torch>=2.2->transformers[torch]->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvshmem-cu12==3.3.20 (from torch>=2.2->transformers[torch]->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.8.90 (from torch>=2.2->transformers[torch]->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch>=2.2->transformers[torch]->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch>=2.2->transformers[torch]->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==3.5.1 (from torch>=2.2->transformers[torch]->-r requirements.txt (line 1))\n",
      "  Downloading triton-3.5.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=2.2->transformers[torch]->-r requirements.txt (line 1))\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/codespace/.local/lib/python3.12/site-packages (from anyio->httpx<1.0.0->datasets->-r requirements.txt (line 2)) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.12/site-packages (from jinja2->torch>=2.2->transformers[torch]->-r requirements.txt (line 1)) (3.0.3)\n",
      "Downloading transformers-4.57.3-py3-none-any.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.22.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading datasets-4.4.2-py3-none-any.whl (512 kB)\n",
      "Downloading dill-0.4.0-py3-none-any.whl (119 kB)\n",
      "Downloading fsspec-2025.10.0-py3-none-any.whl (200 kB)\n",
      "Downloading multiprocess-0.70.18-py312-none-any.whl (150 kB)\n",
      "Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
      "Downloading accelerate-1.12.0-py3-none-any.whl (380 kB)\n",
      "Downloading scikit_learn-1.8.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (8.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.4.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.13.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.7.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (256 kB)\n",
      "Downloading yarl-1.22.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (377 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading frozenlist-1.8.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (242 kB)\n",
      "Downloading joblib-1.5.3-py3-none-any.whl (309 kB)\n",
      "Downloading propcache-0.4.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (221 kB)\n",
      "Downloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (47.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading regex-2025.11.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (803 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.5/803.5 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (507 kB)\n",
      "Downloading scipy-1.16.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.7/35.7 MB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Downloading torch-2.9.1-cp312-cp312-manylinux_2_28_x86_64.whl (899.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m899.7/899.7 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m  \u001b[33m0:00:21\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m  \u001b[33m0:00:13\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m6m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m  \u001b[33m0:00:17\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m  \u001b[33m0:00:03\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m6m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m  \u001b[33m0:00:05\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m  \u001b[33m0:00:05\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m  \u001b[33m0:00:05\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.3/322.3 MB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m  \u001b[33m0:00:06\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (124.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.7/124.7 MB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Downloading triton-3.5.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.5/170.5 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m  \u001b[33m0:00:03\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading networkx-3.6.1-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading filelock-3.20.2-py3-none-any.whl (16 kB)\n",
      "Downloading xxhash-3.6.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (193 kB)\n",
      "Installing collected packages: pytz, nvidia-cusparselt-cu12, mpmath, xxhash, triton, tqdm, threadpoolctl, sympy, safetensors, regex, pyarrow, propcache, nvidia-nvtx-cu12, nvidia-nvshmem-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, multidict, joblib, hf-xet, fsspec, frozenlist, filelock, dill, aiohappyeyeballs, yarl, scipy, pandas, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, multiprocess, huggingface-hub, aiosignal, tokenizers, scikit-learn, nvidia-cusolver-cu12, aiohttp, transformers, torch, datasets, accelerate, evaluate\n",
      "\u001b[2K   \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/50\u001b[0m [triton]t-cu12]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m  WARNING: The scripts proton and proton-viewer are installed in '/usr/local/python/3.12.1/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script tqdm is installed in '/usr/local/python/3.12.1/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/50\u001b[0m [sympy]poolctl]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m  WARNING: The script isympy is installed in '/usr/local/python/3.12.1/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22/50\u001b[0m [numpy]-cublas-cu12]u12]2]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m  WARNING: The scripts f2py and numpy-config are installed in '/usr/local/python/3.12.1/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m42/50\u001b[0m [scikit-learn]ub]2]12]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m  WARNING: The scripts hf, huggingface-cli and tiny-agents are installed in '/usr/local/python/3.12.1/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m46/50\u001b[0m [torch]ormers]er-cu12]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m  WARNING: The scripts transformers and transformers-cli are installed in '/usr/local/python/3.12.1/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m46/50\u001b[0m [torch]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m  WARNING: The scripts torchfrtrace and torchrun are installed in '/usr/local/python/3.12.1/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m48/50\u001b[0m [accelerate]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m  WARNING: The script datasets-cli is installed in '/usr/local/python/3.12.1/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m48/50\u001b[0m [accelerate]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m  WARNING: The scripts accelerate, accelerate-config, accelerate-estimate-memory, accelerate-launch and accelerate-merge-weights are installed in '/usr/local/python/3.12.1/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script evaluate-cli is installed in '/usr/local/python/3.12.1/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50/50\u001b[0m [evaluate]\n",
      "\u001b[1A\u001b[2KSuccessfully installed accelerate-1.12.0 aiohappyeyeballs-2.6.1 aiohttp-3.13.3 aiosignal-1.4.0 datasets-4.4.2 dill-0.4.0 evaluate-0.4.6 filelock-3.20.2 frozenlist-1.8.0 fsspec-2025.10.0 hf-xet-1.2.0 huggingface-hub-0.36.0 joblib-1.5.3 mpmath-1.3.0 multidict-6.7.0 multiprocess-0.70.18 networkx-3.6.1 numpy-2.4.0 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.5 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvshmem-cu12-3.3.20 nvidia-nvtx-cu12-12.8.90 pandas-2.3.3 propcache-0.4.1 pyarrow-22.0.0 pytz-2025.2 regex-2025.11.3 safetensors-0.7.0 scikit-learn-1.8.0 scipy-1.16.3 sympy-1.14.0 threadpoolctl-3.6.0 tokenizers-0.22.2 torch-2.9.1 tqdm-4.67.1 transformers-4.57.3 triton-3.5.1 xxhash-3.6.0 yarl-1.22.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys, subprocess\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-r\", \"requirements.txt\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Wrote:\n",
      " - data/train.csv: 800 rows\n",
      " - data/valid.csv: 200 rows\n",
      "\n",
      "Sample:\n",
      "                                                text  label\n",
      "0                It barely worked and felt terrible.      0\n",
      "1  I'm genuinely disappointed. annoying and frust...      0\n",
      "2           The experience was fantastic. Great job.      1\n",
      "3     This was excellent. The product made me happy.      1\n",
      "4  This was frustrating. The product made me anno...      0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys, subprocess\n",
    "subprocess.check_call([sys.executable, \"make_data.py\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 800/800 [00:00<00:00, 5916.03 examples/s]\n",
      "Map: 100%|██████████| 200/200 [00:00<00:00, 5495.54 examples/s]\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/workspaces/fine-tun/train.py:243: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/usr/local/python/3.12.1/lib/python3.12/site-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      " 25%|██▌       | 25/100 [00:02<00:06, 12.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6818, 'grad_norm': 3.2350997924804688, 'learning_rate': 2.4255319148936168e-05, 'epoch': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 55/100 [00:03<00:01, 30.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6634, 'grad_norm': 1.5191289186477661, 'learning_rate': 1.627659574468085e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 79/100 [00:03<00:00, 30.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6424, 'grad_norm': 3.487560749053955, 'learning_rate': 8.297872340425532e-06, 'epoch': 1.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:04<00:00, 30.92it/s]\n",
      "                                                 \n",
      "100%|██████████| 100/100 [00:04<00:00, 30.92it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 72.32it/s]\u001b[A\n",
      "                                             \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.629, 'grad_norm': 1.8145132064819336, 'learning_rate': 3.1914893617021275e-07, 'epoch': 2.0}\n",
      "{'eval_loss': 0.6074248552322388, 'eval_accuracy': 0.965, 'eval_f1': 0.9651741293532339, 'eval_runtime': 0.1283, 'eval_samples_per_second': 1559.064, 'eval_steps_per_second': 54.567, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:04<00:00, 20.24it/s]\n",
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "100%|██████████| 7/7 [00:00<00:00, 70.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 4.9412, 'train_samples_per_second': 323.806, 'train_steps_per_second': 20.238, 'train_loss': 0.6541444206237793, 'epoch': 2.0}\n",
      "\n",
      "✅ Final eval: {'eval_loss': 0.6074248552322388, 'eval_accuracy': 0.965, 'eval_f1': 0.9651741293532339, 'eval_runtime': 0.1249, 'eval_samples_per_second': 1601.008, 'eval_steps_per_second': 56.035, 'epoch': 2.0}\n",
      "\n",
      "✅ Saved model to: outputs/final_model\n",
      "\n",
      "--- Demo predictions ---\n",
      "\n",
      "Text: I loved this app. It was excellent and reliable.\n",
      "Prob(neg,pos): (0.441, 0.559)\n",
      "\n",
      "Text: This update was horrible and frustrating.\n",
      "Prob(neg,pos): (0.539, 0.461)\n",
      "\n",
      "Text: Better than expected — fantastic experience.\n",
      "Prob(neg,pos): (0.414, 0.586)\n",
      "\n",
      "Text: I regret using this feature. It was confusing and messy.\n",
      "Prob(neg,pos): (0.520, 0.480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys, subprocess\n",
    "subprocess.check_call([sys.executable, \"train.py\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['special_tokens_map.json', 'tokenizer.json', 'training_args.bin', 'tokenizer_config.json', 'vocab.txt', 'model.safetensors', 'config.json']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir(\"outputs/final_model\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'null' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m      1\u001b[39m {\n\u001b[32m      2\u001b[39m   \u001b[33m\"\u001b[39m\u001b[33mcells\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m      3\u001b[39m     {\n\u001b[32m      4\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mcell_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mmarkdown\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      5\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: {},\n\u001b[32m      6\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m      7\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m# BERT Fine-tuning PoC (Synthetic Data)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m      8\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m      9\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThis notebook:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     10\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m1) installs deps\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     11\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m2) generates `data/train.csv` and `data/valid.csv`\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     12\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m3) fine-tunes a small BERT\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     13\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m4) saves model to `outputs/final_model`\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     14\u001b[39m       ]\n\u001b[32m     15\u001b[39m     },\n\u001b[32m     16\u001b[39m     {\n\u001b[32m     17\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mcell_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mcode\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mexecution_count\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43mnull\u001b[49m,\n\u001b[32m     19\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: {},\n\u001b[32m     20\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33moutputs\u001b[39m\u001b[33m\"\u001b[39m: [],\n\u001b[32m     21\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m     22\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mimport sys, os, platform\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     23\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mprint(\u001b[39m\u001b[33m'\u001b[39m\u001b[33mPython:\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, sys.version)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     24\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mprint(\u001b[39m\u001b[33m'\u001b[39m\u001b[33mPlatform:\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, platform.platform())\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     25\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtry:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     26\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    import torch\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     27\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    print(\u001b[39m\u001b[33m'\u001b[39m\u001b[33mTorch:\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, torch.__version__)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     28\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    print(\u001b[39m\u001b[33m'\u001b[39m\u001b[33mCUDA available:\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, torch.cuda.is_available())\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     29\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mexcept Exception as e:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     30\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    print(\u001b[39m\u001b[33m'\u001b[39m\u001b[33mTorch not installed yet:\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, e)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     31\u001b[39m       ]\n\u001b[32m     32\u001b[39m     },\n\u001b[32m     33\u001b[39m     {\n\u001b[32m     34\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mcell_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mmarkdown\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     35\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: {},\n\u001b[32m     36\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m     37\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m## Install dependencies\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     38\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIf you’re on JupyterLab/VSCode Notebook, `\u001b[39m\u001b[33m%\u001b[39m\u001b[33mpip` installs into the notebook kernel environment.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     39\u001b[39m       ]\n\u001b[32m     40\u001b[39m     },\n\u001b[32m     41\u001b[39m     {\n\u001b[32m     42\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mcell_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mcode\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     43\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mexecution_count\u001b[39m\u001b[33m\"\u001b[39m: null,\n\u001b[32m     44\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: {},\n\u001b[32m     45\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33moutputs\u001b[39m\u001b[33m\"\u001b[39m: [],\n\u001b[32m     46\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m     47\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m%\u001b[39m\u001b[33mpip install -r requirements.txt\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     48\u001b[39m       ]\n\u001b[32m     49\u001b[39m     },\n\u001b[32m     50\u001b[39m     {\n\u001b[32m     51\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mcell_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mmarkdown\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     52\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: {},\n\u001b[32m     53\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m     54\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m## Generate synthetic train/valid CSVs\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     55\u001b[39m       ]\n\u001b[32m     56\u001b[39m     },\n\u001b[32m     57\u001b[39m     {\n\u001b[32m     58\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mcell_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mcode\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     59\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mexecution_count\u001b[39m\u001b[33m\"\u001b[39m: null,\n\u001b[32m     60\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: {},\n\u001b[32m     61\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33moutputs\u001b[39m\u001b[33m\"\u001b[39m: [],\n\u001b[32m     62\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m     63\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m!python make_data.py\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     64\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     65\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mimport pandas as pd\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     66\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mprint(\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mnTrain head:\u001b[39m\u001b[33m'\u001b[39m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     67\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mdisplay(pd.read_csv(\u001b[39m\u001b[33m'\u001b[39m\u001b[33mdata/train.csv\u001b[39m\u001b[33m'\u001b[39m\u001b[33m).head())\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     68\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mprint(\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mnValid head:\u001b[39m\u001b[33m'\u001b[39m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     69\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mdisplay(pd.read_csv(\u001b[39m\u001b[33m'\u001b[39m\u001b[33mdata/valid.csv\u001b[39m\u001b[33m'\u001b[39m\u001b[33m).head())\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     70\u001b[39m       ]\n\u001b[32m     71\u001b[39m     },\n\u001b[32m     72\u001b[39m     {\n\u001b[32m     73\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mcell_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mmarkdown\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     74\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: {},\n\u001b[32m     75\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m     76\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m## Fine-tune BERT (PoC)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     77\u001b[39m       ]\n\u001b[32m     78\u001b[39m     },\n\u001b[32m     79\u001b[39m     {\n\u001b[32m     80\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mcell_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mcode\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     81\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mexecution_count\u001b[39m\u001b[33m\"\u001b[39m: null,\n\u001b[32m     82\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: {},\n\u001b[32m     83\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33moutputs\u001b[39m\u001b[33m\"\u001b[39m: [],\n\u001b[32m     84\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m     85\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m!python train.py\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     86\u001b[39m       ]\n\u001b[32m     87\u001b[39m     },\n\u001b[32m     88\u001b[39m     {\n\u001b[32m     89\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mcell_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mmarkdown\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     90\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: {},\n\u001b[32m     91\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m     92\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m## Load saved model and run quick predictions\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     93\u001b[39m       ]\n\u001b[32m     94\u001b[39m     },\n\u001b[32m     95\u001b[39m     {\n\u001b[32m     96\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mcell_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mcode\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     97\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mexecution_count\u001b[39m\u001b[33m\"\u001b[39m: null,\n\u001b[32m     98\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: {},\n\u001b[32m     99\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33moutputs\u001b[39m\u001b[33m\"\u001b[39m: [],\n\u001b[32m    100\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m    101\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mimport torch\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    102\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    103\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    104\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmodel_dir = \u001b[39m\u001b[33m'\u001b[39m\u001b[33moutputs/final_model\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    105\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtokenizer = AutoTokenizer.from_pretrained(model_dir)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    106\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmodel = AutoModelForSequenceClassification.from_pretrained(model_dir)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    107\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    108\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mdevice = \u001b[39m\u001b[33m'\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m'\u001b[39m\u001b[33m if torch.cuda.is_available() else \u001b[39m\u001b[33m'\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    109\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmodel.to(device)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    110\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmodel.eval()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    111\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    112\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtexts = [\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    113\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    \u001b[39m\u001b[33m'\u001b[39m\u001b[33mI loved this product. It was excellent and reliable.\u001b[39m\u001b[33m'\u001b[39m\u001b[33m,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    114\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    \u001b[39m\u001b[33m'\u001b[39m\u001b[33mThis service was awful and frustrating.\u001b[39m\u001b[33m'\u001b[39m\u001b[33m,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    115\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    \u001b[39m\u001b[33m'\u001b[39m\u001b[33mBetter than expected — fantastic experience.\u001b[39m\u001b[33m'\u001b[39m\u001b[33m,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    116\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    \u001b[39m\u001b[33m'\u001b[39m\u001b[33mI regret using this feature. It was confusing and messy.\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    117\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    118\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    119\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33menc = tokenizer(texts, return_tensors=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, padding=True, truncation=True)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    120\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33menc = \u001b[39m\u001b[33m{\u001b[39m\u001b[33mk: v.to(device) for k, v in enc.items()}\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    121\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    122\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mwith torch.no_grad():\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    123\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    logits = model(**enc).logits\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    124\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    probs = torch.softmax(logits, dim=-1).cpu().numpy()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    125\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    126\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mfor t, p in zip(texts, probs):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    127\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    print(\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mnText:\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, t)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    128\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    print(\u001b[39m\u001b[33m'\u001b[39m\u001b[33mProb(neg,pos):\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, (float(p[0]), float(p[1])))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    129\u001b[39m       ]\n\u001b[32m    130\u001b[39m     }\n\u001b[32m    131\u001b[39m   ],\n\u001b[32m    132\u001b[39m   \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m    133\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mkernelspec\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m    134\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mdisplay_name\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mPython 3\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    135\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mlanguage\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mpython\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    136\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mpython3\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    137\u001b[39m     },\n\u001b[32m    138\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mlanguage_info\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m    139\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mpython\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    140\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mversion\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m3.x\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    141\u001b[39m     }\n\u001b[32m    142\u001b[39m   },\n\u001b[32m    143\u001b[39m   \u001b[33m\"\u001b[39m\u001b[33mnbformat\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m4\u001b[39m,\n\u001b[32m    144\u001b[39m   \u001b[33m\"\u001b[39m\u001b[33mnbformat_minor\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m5\u001b[39m\n\u001b[32m    145\u001b[39m }\n",
      "\u001b[31mNameError\u001b[39m: name 'null' is not defined"
     ]
    }
   ],
   "source": [
    "# {\n",
    "#   \"cells\": [\n",
    "#     {\n",
    "#       \"cell_type\": \"markdown\",\n",
    "#       \"metadata\": {},\n",
    "#       \"source\": [\n",
    "#         \"# BERT Fine-tuning PoC (Synthetic Data)\\n\",\n",
    "#         \"\\n\",\n",
    "#         \"This notebook:\\n\",\n",
    "#         \"1) installs deps\\n\",\n",
    "#         \"2) generates `data/train.csv` and `data/valid.csv`\\n\",\n",
    "#         \"3) fine-tunes a small BERT\\n\",\n",
    "#         \"4) saves model to `outputs/final_model`\\n\"\n",
    "#       ]\n",
    "#     },\n",
    "#     {\n",
    "#       \"cell_type\": \"code\",\n",
    "#       \"execution_count\": null,\n",
    "#       \"metadata\": {},\n",
    "#       \"outputs\": [],\n",
    "#       \"source\": [\n",
    "#         \"import sys, os, platform\\n\",\n",
    "#         \"print('Python:', sys.version)\\n\",\n",
    "#         \"print('Platform:', platform.platform())\\n\",\n",
    "#         \"try:\\n\",\n",
    "#         \"    import torch\\n\",\n",
    "#         \"    print('Torch:', torch.__version__)\\n\",\n",
    "#         \"    print('CUDA available:', torch.cuda.is_available())\\n\",\n",
    "#         \"except Exception as e:\\n\",\n",
    "#         \"    print('Torch not installed yet:', e)\\n\"\n",
    "#       ]\n",
    "#     },\n",
    "#     {\n",
    "#       \"cell_type\": \"markdown\",\n",
    "#       \"metadata\": {},\n",
    "#       \"source\": [\n",
    "#         \"## Install dependencies\\n\",\n",
    "#         \"If you’re on JupyterLab/VSCode Notebook, `%pip` installs into the notebook kernel environment.\"\n",
    "#       ]\n",
    "#     },\n",
    "#     {\n",
    "#       \"cell_type\": \"code\",\n",
    "#       \"execution_count\": null,\n",
    "#       \"metadata\": {},\n",
    "#       \"outputs\": [],\n",
    "#       \"source\": [\n",
    "#         \"%pip install -r requirements.txt\"\n",
    "#       ]\n",
    "#     },\n",
    "#     {\n",
    "#       \"cell_type\": \"markdown\",\n",
    "#       \"metadata\": {},\n",
    "#       \"source\": [\n",
    "#         \"## Generate synthetic train/valid CSVs\"\n",
    "#       ]\n",
    "#     },\n",
    "#     {\n",
    "#       \"cell_type\": \"code\",\n",
    "#       \"execution_count\": null,\n",
    "#       \"metadata\": {},\n",
    "#       \"outputs\": [],\n",
    "#       \"source\": [\n",
    "#         \"!python make_data.py\\n\",\n",
    "#         \"\\n\",\n",
    "#         \"import pandas as pd\\n\",\n",
    "#         \"print('\\\\nTrain head:')\\n\",\n",
    "#         \"display(pd.read_csv('data/train.csv').head())\\n\",\n",
    "#         \"print('\\\\nValid head:')\\n\",\n",
    "#         \"display(pd.read_csv('data/valid.csv').head())\\n\"\n",
    "#       ]\n",
    "#     },\n",
    "#     {\n",
    "#       \"cell_type\": \"markdown\",\n",
    "#       \"metadata\": {},\n",
    "#       \"source\": [\n",
    "#         \"## Fine-tune BERT (PoC)\"\n",
    "#       ]\n",
    "#     },\n",
    "#     {\n",
    "#       \"cell_type\": \"code\",\n",
    "#       \"execution_count\": null,\n",
    "#       \"metadata\": {},\n",
    "#       \"outputs\": [],\n",
    "#       \"source\": [\n",
    "#         \"!python train.py\"\n",
    "#       ]\n",
    "#     },\n",
    "#     {\n",
    "#       \"cell_type\": \"markdown\",\n",
    "#       \"metadata\": {},\n",
    "#       \"source\": [\n",
    "#         \"## Load saved model and run quick predictions\"\n",
    "#       ]\n",
    "#     },\n",
    "#     {\n",
    "#       \"cell_type\": \"code\",\n",
    "#       \"execution_count\": null,\n",
    "#       \"metadata\": {},\n",
    "#       \"outputs\": [],\n",
    "#       \"source\": [\n",
    "#         \"import torch\\n\",\n",
    "#         \"from transformers import AutoTokenizer, AutoModelForSequenceClassification\\n\",\n",
    "#         \"\\n\",\n",
    "#         \"model_dir = 'outputs/final_model'\\n\",\n",
    "#         \"tokenizer = AutoTokenizer.from_pretrained(model_dir)\\n\",\n",
    "#         \"model = AutoModelForSequenceClassification.from_pretrained(model_dir)\\n\",\n",
    "#         \"\\n\",\n",
    "#         \"device = 'cuda' if torch.cuda.is_available() else 'cpu'\\n\",\n",
    "#         \"model.to(device)\\n\",\n",
    "#         \"model.eval()\\n\",\n",
    "#         \"\\n\",\n",
    "#         \"texts = [\\n\",\n",
    "#         \"    'I loved this product. It was excellent and reliable.',\\n\",\n",
    "#         \"    'This service was awful and frustrating.',\\n\",\n",
    "#         \"    'Better than expected — fantastic experience.',\\n\",\n",
    "#         \"    'I regret using this feature. It was confusing and messy.'\\n\",\n",
    "#         \"]\\n\",\n",
    "#         \"\\n\",\n",
    "#         \"enc = tokenizer(texts, return_tensors='pt', padding=True, truncation=True)\\n\",\n",
    "#         \"enc = {k: v.to(device) for k, v in enc.items()}\\n\",\n",
    "#         \"\\n\",\n",
    "#         \"with torch.no_grad():\\n\",\n",
    "#         \"    logits = model(**enc).logits\\n\",\n",
    "#         \"    probs = torch.softmax(logits, dim=-1).cpu().numpy()\\n\",\n",
    "#         \"\\n\",\n",
    "#         \"for t, p in zip(texts, probs):\\n\",\n",
    "#         \"    print('\\\\nText:', t)\\n\",\n",
    "#         \"    print('Prob(neg,pos):', (float(p[0]), float(p[1])))\\n\"\n",
    "#       ]\n",
    "#     }\n",
    "#   ],\n",
    "#   \"metadata\": {\n",
    "#     \"kernelspec\": {\n",
    "#       \"display_name\": \"Python 3\",\n",
    "#       \"language\": \"python\",\n",
    "#       \"name\": \"python3\"\n",
    "#     },\n",
    "#     \"language_info\": {\n",
    "#       \"name\": \"python\",\n",
    "#       \"version\": \"3.x\"\n",
    "#     }\n",
    "#   },\n",
    "#   \"nbformat\": 4,\n",
    "#   \"nbformat_minor\": 5\n",
    "# }\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
